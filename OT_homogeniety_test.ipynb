{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from numpy.linalg import norm\n",
    "from numpy.random import default_rng\n",
    "from random import choice\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import pickle\n",
    "import importlib\n",
    "import os, sys\n",
    "import ot\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rc\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from utils import * \n",
    "\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_matrix(X, Y):\n",
    "    x = np.shape(X)[0]\n",
    "    y = np.shape(Y)[0]\n",
    "    cost  = [[norm(X[i] - Y[j])**2 for i in range(x)] for j in range(y)]\n",
    "    return(cost)\n",
    "\n",
    "def gen_random_ball(dimension, num_points, rs = None, radius = 1):\n",
    "    #from numpy import random, linalg\n",
    "    # First generate random directions by normalizing the length of a\n",
    "    # vector of random-normal values (these distribute evenly on ball)\n",
    "    #rs - random state, None by default\n",
    "    rng = default_rng(rs)\n",
    "    random_directions = rng.standard_normal(size=(dimension, num_points))\n",
    "    random_directions /= norm(random_directions, axis=0)\n",
    "    # Second generate a random radius with probability proportional to\n",
    "    # the surface area of a ball with a given radius.\n",
    "    random_radii = rng.random(num_points) ** (1/dimension)\n",
    "    # Return the list of random (direction & length) points.\n",
    "    ball = radius * (random_directions * random_radii).T\n",
    "    return ball\n",
    "\n",
    "def split_data_randomly(d):\n",
    "    #function randomly splits 2n points into two groups of n points each \n",
    "    #d - data\n",
    "    ind = np.arange(d.shape[0])\n",
    "    np.random.shuffle(ind)\n",
    "    n = int(len(d)/2)\n",
    "    ind1 = ind[:n]\n",
    "    ind2 = ind[n:]\n",
    "\n",
    "    s1 = d[ind1]\n",
    "    s2 = d[ind2]\n",
    "    return s1, s2\n",
    "\n",
    "#see Algorithm 3 (Section 2.2)\n",
    "def compute_critical_level(ball, N, alpha):\n",
    "    #N - num of iterations for resampling\n",
    "    n = int(len(ball)/2)\n",
    "    stat = []\n",
    "    m0     = [1/n] * n\n",
    "    m1     = [1/n] * n\n",
    "    \n",
    "    for i in range(0, N):\n",
    "        s1, s2 = split_data_randomly(d = ball)\n",
    "        M = cost_matrix(s1, s2)\n",
    "        M = np.array(M)\n",
    "        plan = ot.emd2(m0, m1, M) #ot distance\n",
    "        stat.append(plan)\n",
    "\n",
    "    q = (1 - alpha)*100\n",
    "    cr_level = np.percentile(stat, q)\n",
    "    return cr_level\n",
    "\n",
    "#returns OT plan (if mode = plan) and OT distance (if mode = distance)\n",
    "def computeOT(s, t, mode):\n",
    "    #returns OT plan (if mode = plan) and OT distance (if mode = distance)\n",
    "    n = len(s)\n",
    "    k = len(t)\n",
    "    m0     = [1/n] * n\n",
    "    m1     = [1/k] * k\n",
    "    M = cost_matrix(s, t)\n",
    "    M = np.array(M)\n",
    "    if mode == 'plan':\n",
    "        plan = ot.emd(m0, m1, M) #transport plan\n",
    "    elif mode == 'distance':\n",
    "        plan = ot.emd2(m0, m1, M)\n",
    "    return plan\n",
    "\n",
    "\n",
    "# #returns OT distance\n",
    "# def computeOT2(s, t):\n",
    "#     n = len(s)\n",
    "#     k = len(t)\n",
    "#     m0     = [1/n] * n\n",
    "#     m1     = [1/k] * k\n",
    "#     M = cost_matrix(s, t)\n",
    "#     M = np.array(M)\n",
    "#     plan = ot.emd2(m0, m1, M) #transport plan\n",
    "#     return plan\n",
    "\n",
    "#OT Map\n",
    "\n",
    "\n",
    "\n",
    "#s1 - first sample, s2 -second sample, t - target distribution\n",
    "def compute_distance(s1, s2, t):\n",
    "    ##Step 2 in Alogorithm 3: OT distance between ball partitions \n",
    "    ## induced by the transport of two data distributions\n",
    "    L = len(s1)\n",
    "    s = np.concatenate((s1, s2), axis = 0)\n",
    "    plan = computeOT(s = t, t = s, mode = 'plan')\n",
    "    ind = [np.nonzero(plan[i])[0][0] for i in range(2*L)] #indices of assigned distributions\n",
    "    \n",
    "    #split target t\n",
    "    ind_t1 = []\n",
    "    ind_t2 = []\n",
    "    for i in range(0, len(s)):\n",
    "        if i < L:\n",
    "            ind_t1.append(ind[i])\n",
    "        else:\n",
    "            ind_t2.append(ind[i])\n",
    "   \n",
    "    t1 = t[ind_t1]\n",
    "    t2 = t[ind_t2]   \n",
    "    dst_fin = computeOT(s = t1, t = t2, mode = 'distance')\n",
    "    \n",
    "    return dst_fin\n",
    "\n",
    "#Aux functions to plot Img. 7\n",
    "\n",
    "def decompose(X, method = 'numpy.eigh'):\n",
    "    \"\"\"Eigenvalue decomposition of X\"\"\"\n",
    "    if method == \"tf.eig\":\n",
    "        import tensorflow as tf\n",
    "        A_tf = tf.convert_to_tensor(X)\n",
    "        eigvals, eigvects = tf.linalg.eig(A_tf)\n",
    "        eigvals, eigvects = eigvals.numpy(), eigvects.numpy()\n",
    "    elif method == \"tf.eigh\":\n",
    "        import tensorflow as tf\n",
    "        A_tf = tf.convert_to_tensor(X)\n",
    "        eigvals, eigvects = tf.linalg.eigh(A_tf)\n",
    "        eigvals, eigvects = eigvals.numpy(), eigvects.numpy()\n",
    "    elif method == \"numpy.eig\":\n",
    "        eigvals, eigvects = np.linalg.eig(X)\n",
    "    elif method == \"numpy.eigh\":\n",
    "        eigvals, eigvects = np.linalg.eigh(X)\n",
    "    else:\n",
    "        raise NotImplementedError('Unknown method: ' + method)\n",
    "    return eigvals, eigvects\n",
    "\n",
    "def sqrtmInv(X, method='numpy.eigh'):\n",
    "    \"\"\"Inversion of a square root of X\"\"\"\n",
    "    eigval, eigvects = decompose(X, method)\n",
    "    Y = (eigvects / np.sqrt(np.maximum(eigval, 0))[np.newaxis,:]).dot(eigvects.T)\n",
    "    return(Y)\n",
    "\n",
    "def sqrtm(X, method='numpy.eigh'):\n",
    "    \"\"\"Square root of a symmetric matrix\"\"\"\n",
    "    eigval, eigvects = decompose(X, method)\n",
    "    Y = (eigvects * np.sqrt(np.maximum(eigval, 0))[np.newaxis,:]).dot(eigvects.T)\n",
    "    return(Y)\n",
    "\n",
    "\n",
    "#2-Wasserstein distance between two Gaussian distributions\n",
    "def BW(K1, K2, method='numpy.eigh'):\n",
    "    \"\"\"Compute the Bures-Wasserstein distance between covariance matrices\"\"\"\n",
    "    Q = sqrtm(K1, method)\n",
    "    d = np.sqrt(np.maximum(0, K1.trace() + K2.trace() - 2 * sqrtm(Q.dot(K2).dot(Q), method).trace()))\n",
    "    return d\n",
    "\n",
    "def OT_map(V, U):\n",
    "    #map from V to U\n",
    "    sqU = sqrtm(U,method='numpy.eigh')\n",
    "    Cn  =  (sqU @ V) @ sqU\n",
    "    Z = sqrtmInv(Cn, method='numpy.eigh')\n",
    "#     pinvCn = pinvsq(Cn)\n",
    "    T = (sqU @ Z) @ sqU\n",
    "    return T\n",
    "\n",
    "def OT_geod(V, T, t):\n",
    "    E = np.array([[1,0],[0, 1]])\n",
    "    Z = E * (1-t) + t*T\n",
    "    V = Z @ V \n",
    "    W = V @ Z\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section 2.2.2\n",
    "\n",
    "#We consider two 2D point clouds coming from centred Gaussian distributions\n",
    "\n",
    "\n",
    "#num of points in each sample\n",
    "#ATTENTION: by now we assume the num of points in each sample are eqaual\n",
    "\n",
    "m = [0, 0]\n",
    "\n",
    "#sample X\n",
    "C1=np.array([[5, 2], [2, 2]])\n",
    "\n",
    "#sample Y\n",
    "C2=np.array([[12.0, 4], [4, 15.0]])\n",
    "m = [0, 0]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance of different sample sizes (Img. 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different sample sizes\n",
    "grd = [10, 20, 30, 50, 70]\n",
    "\n",
    "#store distribution of test values\n",
    "test_values  = []\n",
    "\n",
    "#num of iterations to estimate the distribution of the test\n",
    "Z = 100\n",
    "\n",
    "#store critical level for each sample size\n",
    "critical_levels = []\n",
    "for g in grd:\n",
    "    #target\n",
    "    b = gen_random_ball(dimension=2, num_points=2*g, rs=None, radius = 1) #(see Algorithm 2, steps 2) \n",
    "    cr_l = compute_critical_level(ball = b, N=1500, alpha=.05) #(see Algorithm 3) \n",
    "    critical_levels.append(cr_l)\n",
    "    \n",
    "    #resampling for a given sample size: store test values \n",
    "    dummy = []\n",
    "    for j in range(0, Z):\n",
    "        #generate two samples of g points each, X = s1, Y = s2\n",
    "        s1 = np.random.multivariate_normal(m, C1, g)\n",
    "        s2 = np.random.multivariate_normal(m, C2, g)\n",
    "        \n",
    "        #compute test statistics (see Algorithm 2, steps 1, 3, 4, 5) \n",
    "        dst = compute_distance(s1 = s1, s2 =s2, t=b)\n",
    "        dummy.append(dst)\n",
    "    test_values.append(dummy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot violin plots (see Img. 6)\n",
    "data = test_values\n",
    "\n",
    "# Create four separate subplots for violin plots in a row\n",
    "fig, axs = plt.subplots(1, len(grd), figsize=(20, 6))\n",
    "\n",
    "# Plot violin plots and add red horizontal line for the 0.95 quantile for each set of data\n",
    "for i, ax in enumerate(axs):\n",
    "    parts = ax.violinplot(data[i], showmeans=False, showmedians=True)\n",
    "    quantile_95 = np.percentile(data[i], 95)  # Calculate 0.95 quantile\n",
    "    ax.axhline(y=quantile_95, color='blue', linestyle='-', linewidth=2)  # Add red horizontal line at 0.95 quantile\n",
    "    ax.axhline(y=critical_levels[i],  color='red', linestyle='--', linewidth=2)  # Add red horizontal line at y=3.5\n",
    "\n",
    "\n",
    "    ax.set_title(f'n = {grd[i]}')\n",
    "    ax.set_xticks([1])\n",
    "    ax.set_xticklabels([''])\n",
    "    ax.set_ylabel(r'Distribution of $d_{W}(U_{C_1}, U_{C_2})$')\n",
    "\n",
    "    # Customize the appearance of the violin plots\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor('skyblue')  # Set violin color\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(1)  # Set transparency\n",
    "        pc.set_linewidth(1.5)  # Set edge linewidth\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance depending on the size of a change point (Img. 7 and Img.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Change point is simulated as a movement over geodesic in 2-Wasserstein space \n",
    "#connecting the data generating distributions N(0, C1) and N(0, C2)\n",
    "\n",
    "\n",
    "#step at geodesic\n",
    "grd = [0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1]\n",
    "\n",
    "#find optimal map between C1 and C2\n",
    "mapT = OT_map(C1, C2)\n",
    "\n",
    "#store change point values\n",
    "stat_BW = []\n",
    "\n",
    "#store test statistic values\n",
    "stat_U  = []\n",
    "\n",
    "#num of iterations to estimate the distribution of the test\n",
    "Z = 100\n",
    "\n",
    "#num of points in each sample\n",
    "num_points = 80\n",
    "\n",
    "# #generate points from uniform distributopm on a ball\n",
    "b = gen_random_ball(dimension=2, num_points=2*num_points, rs=None, radius = 1) #(see Algorithm 2, steps 2) \n",
    "\n",
    "#compute critical level\n",
    "cr_l = compute_critical_level(ball = b, N=1500, alpha=.05) #(see Algorithm 3) \n",
    "\n",
    "#move along geodesic\n",
    "for t in grd:\n",
    "    if t == 0:\n",
    "        gC = C1\n",
    "    elif t == 1:\n",
    "        gC = C2\n",
    "    else: \n",
    "         gC = OT_geod(C1, mapT, t)\n",
    "    \n",
    "    stat_BW.append(BW(C1, gC))#distance between data generating distributions\n",
    "    dummy = []\n",
    "    for j in range(0, Z):\n",
    "        s1 = np.random.multivariate_normal(m, C1, num_points)\n",
    "        s2 = np.random.multivariate_normal(m, gC, num_points)\n",
    "        dst = compute_distance(s1 = s1, s2 =s2, t=b)\n",
    "        dummy.append(dst)\n",
    "    stat_U.append(dummy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Img. 7\n",
    "\n",
    "data_to_plot = np.array(stat_BW)\n",
    "\n",
    "\n",
    "# Create a color normalization instance\n",
    "nrm = Normalize(vmin=data_to_plot.min(), vmax=data_to_plot.max())\n",
    "colors = plt.cm.viridis_r(nrm(data_to_plot))\n",
    "\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot the ellipses with varying colors and sizes\n",
    "k = -1\n",
    "for g in grd:\n",
    "    k+=1\n",
    "    gC = OT_geod(C1, mapT, g)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(gC)\n",
    "    theta = np.degrees(np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0]))\n",
    "    ellipse = Ellipse((0, 0), 2 * np.sqrt(2.5 * eigenvalues[1]), 2 * np.sqrt(2.5 * eigenvalues[0]),\n",
    "                      angle=theta, color=colors[k], fill = False)\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "# Set axis limits\n",
    "ax.set_xlim(-10, 10)\n",
    "ax.set_ylim(-10, 10)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_title(r'2-Wasserstein geodesic $C_t$ between $C_0$ and $C_1$')\n",
    "\n",
    "# # Add a colorbar\n",
    "\n",
    "sm = ScalarMappable(norm=nrm, cmap=plt.cm.viridis_r)\n",
    "sm.set_array([])  # empty array for the mappable\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label(r'$d_W(\\mathcal{N}(0, C_0), \\mathcal{N}(0, C_t))$')\n",
    "\n",
    "# cbar = plt.colorbar(sm)\n",
    "# cbar.set_label('2-Wasserstein distance')\n",
    "legend_elements = [\n",
    "    Patch(facecolor=colors[0], edgecolor='white', label=r'Covariance $C_0$'),\n",
    "    Patch(facecolor=colors[-1], edgecolor='white', label=r'Covariance $C_1$')\n",
    "]\n",
    "# Show the plot\n",
    "ax.legend(handles=legend_elements)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size for violin plots (width x height in inches)\n",
    "fig_violin, ax_violin = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "num_ticks = len(grd)\n",
    "# Create random data for the violin plots (number of data points = number of ellipses)\n",
    "data_to_plot = stat_U\n",
    "quantiles = [np.percentile(dataset, 95) for dataset in data_to_plot]\n",
    "# Create violin plots with the same colors as the ellipses\n",
    "violin_parts = ax_violin.violinplot(data_to_plot, showmeans=False, showmedians=False)\n",
    "for i, pc in enumerate(violin_parts['bodies']):\n",
    "    pc.set_facecolor(colors[i])\n",
    "    pc.set_edgecolor('black')\n",
    "    ax_violin.plot([i + 1], [quantiles[i]], marker='o', markersize=8, color='red', zorder=3)\n",
    "\n",
    "\n",
    "# Set axis limits for violin plots\n",
    "ax_violin.set_xticks(np.arange(1, num_ticks + 1))\n",
    "ax_violin.set_xticklabels([fr'$t = {(i-1)/10}$' for i in range(1, num_ticks + 1)])\n",
    "ax_violin.set_xlabel(r'$2$-Wasserstein geodesic in original space')\n",
    "ax_violin.set_ylabel('Distributions')\n",
    "ax_violin.set_title(r'Distribution of $d_{W}(U_{C_1}, U_{C_t})$, sample sizes $n=80$')\n",
    "\n",
    "ax_violin.axhline(y=cr_l, color='red', linestyle='--', linewidth=1, label='Critical level')\n",
    "\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
