{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Снижение дисперсии при A/B тестировании с помощью контрольных перменных, описанное в разделе 3 отчета о НИР."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что в процессе проведения A/B теста нам доступны пары наблюдений $(X_i, Y_i)_{i=1}^n$, где $X_i$ и $Y_i~-~$ признаки и значение целевой метрики для $i$-го пользователя соотвественно. Суть метода контрольных переменных заключается в том, чтобы на основании значения признаков $X$ построить такую случайную величину $\\zeta$ с известным математическим ожиданием и конечной дисперсией, что\n",
    "$$\n",
    "Var(Y +\\zeta) \\ll Var(Y)\\,.\n",
    "$$\n",
    "В таком случае выводы о наличие эффекта при A/B тестировании будут делаться на основании разницы в средних, обнаруживаемой в наборе величин $\\{Y_i + \\zeta_i\\}$, обладающих меньшей дисперсией. Таким образом, за счет снижения дисперсии $\\{Y_i + \\zeta_i\\}$ можно снизить размер выборки, требуемый для получения статистически значимых результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "#для запуска части ноутбука с генерацией данных раскомментируйте\n",
    "#import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import normalize, OrdinalEncoder, OneHotEncoder\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.validation import _num_samples, check_array\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "from sklearn.model_selection._split import _BaseKFold, _RepeatedSplits, \\\n",
    "    BaseShuffleSplit, _validate_shuffle_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код в следующей ячейке копирует (открытую) библиотеку iterstrat, распространяемую под открытой лицензией BSD-3. Подробнее с кодом библиотеки можно ознакомиться по ссылке https://github.com/trent-b/iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This file includes multilabel cross validators based on an implementation of\n",
    "the Iterative Stratification algorithm described in the following paper:\n",
    "Sechidis K., Tsoumakas G., Vlahavas I. (2011) On the Stratification of Multi-\n",
    "Label Data. In: Gunopulos D., Hofmann T., Malerba D., Vazirgiannis M. (eds)\n",
    "Machine Learning and Knowledge Discovery in Databases. ECML PKDD 2011. Lecture\n",
    "Notes in Computer Science, vol 6913. Springer, Berlin, Heidelberg.\n",
    "\n",
    "From scikit-learn 0.19.0, StratifiedKFold, RepeatedStratifiedKFold, and\n",
    "StratifiedShuffleSplit were copied and modified, retaining compatibility\n",
    "with scikit-learn.\n",
    "\n",
    "Attribution to authors of scikit-learn/model_selection/_split.py under BSD 3 clause:\n",
    "    Alexandre Gramfort <alexandre.gramfort@inria.fr>,\n",
    "    Gael Varoquaux <gael.varoquaux@normalesup.org>,\n",
    "    Olivier Grisel <olivier.grisel@ensta.org>,\n",
    "    Raghav RV <rvraghav93@gmail.com>\n",
    "\"\"\"\n",
    "\n",
    "# Author: Trent J. Bradberry <trentjason@hotmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "def IterativeStratification(labels, r, random_state):\n",
    "    \"\"\"This function implements the Iterative Stratification algorithm described\n",
    "    in the following paper:\n",
    "    Sechidis K., Tsoumakas G., Vlahavas I. (2011) On the Stratification of\n",
    "    Multi-Label Data. In: Gunopulos D., Hofmann T., Malerba D., Vazirgiannis M.\n",
    "    (eds) Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n",
    "    2011. Lecture Notes in Computer Science, vol 6913. Springer, Berlin,\n",
    "    Heidelberg.\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = labels.shape[0]\n",
    "    test_folds = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    # Calculate the desired number of examples at each subset\n",
    "    c_folds = r * n_samples\n",
    "\n",
    "    # Calculate the desired number of examples of each label at each subset\n",
    "    c_folds_labels = np.outer(r, labels.sum(axis=0))\n",
    "\n",
    "    labels_not_processed_mask = np.ones(n_samples, dtype=bool)\n",
    "\n",
    "    while np.any(labels_not_processed_mask):\n",
    "        # Find the label with the fewest (but at least one) remaining examples,\n",
    "        # breaking ties randomly\n",
    "        num_labels = labels[labels_not_processed_mask].sum(axis=0)\n",
    "\n",
    "        # Handle case where only all-zero labels are left by distributing\n",
    "        # across all folds as evenly as possible (not in original algorithm but\n",
    "        # mentioned in the text). (By handling this case separately, some\n",
    "        # code redundancy is introduced; however, this approach allows for\n",
    "        # decreased execution time when there are a relatively large number\n",
    "        # of all-zero labels.)\n",
    "        if num_labels.sum() == 0:\n",
    "            sample_idxs = np.where(labels_not_processed_mask)[0]\n",
    "\n",
    "            for sample_idx in sample_idxs:\n",
    "                fold_idx = np.where(c_folds == c_folds.max())[0]\n",
    "\n",
    "                if fold_idx.shape[0] > 1:\n",
    "                    fold_idx = fold_idx[random_state.choice(fold_idx.shape[0])]\n",
    "\n",
    "                test_folds[sample_idx] = fold_idx\n",
    "                c_folds[fold_idx] -= 1\n",
    "\n",
    "            break\n",
    "\n",
    "        label_idx = np.where(num_labels == num_labels[np.nonzero(num_labels)].min())[0]\n",
    "        if label_idx.shape[0] > 1:\n",
    "            label_idx = label_idx[random_state.choice(label_idx.shape[0])]\n",
    "\n",
    "        sample_idxs = np.where(np.logical_and(labels[:, label_idx].flatten(), labels_not_processed_mask))[0]\n",
    "\n",
    "        for sample_idx in sample_idxs:\n",
    "            # Find the subset(s) with the largest number of desired examples\n",
    "            # for this label, breaking ties by considering the largest number\n",
    "            # of desired examples, breaking further ties randomly\n",
    "            label_folds = c_folds_labels[:, label_idx]\n",
    "            fold_idx = np.where(label_folds == label_folds.max())[0]\n",
    "\n",
    "            if fold_idx.shape[0] > 1:\n",
    "                temp_fold_idx = np.where(c_folds[fold_idx] ==\n",
    "                                         c_folds[fold_idx].max())[0]\n",
    "                fold_idx = fold_idx[temp_fold_idx]\n",
    "\n",
    "                if temp_fold_idx.shape[0] > 1:\n",
    "                    fold_idx = fold_idx[random_state.choice(temp_fold_idx.shape[0])]\n",
    "\n",
    "            test_folds[sample_idx] = fold_idx\n",
    "            labels_not_processed_mask[sample_idx] = False\n",
    "\n",
    "            # Update desired number of examples\n",
    "            c_folds_labels[fold_idx, labels[sample_idx]] -= 1\n",
    "            c_folds[fold_idx] -= 1\n",
    "\n",
    "    return test_folds\n",
    "\n",
    "\n",
    "class MultilabelStratifiedKFold(_BaseKFold):\n",
    "    \"\"\"Multilabel stratified K-Folds cross-validator\n",
    "    Provides train/test indices to split multilabel data into train/test sets.\n",
    "    This cross-validation object is a variation of KFold that returns\n",
    "    stratified folds for multilabel data. The folds are made by preserving\n",
    "    the percentage of samples for each label.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=3\n",
    "        Number of folds. Must be at least 2.\n",
    "    shuffle : boolean, optional\n",
    "        Whether to shuffle each stratification of the data before splitting\n",
    "        into batches.\n",
    "    random_state : int, RandomState instance or None, optional, default=None\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`. Unlike StratifiedKFold that only uses random_state\n",
    "        when ``shuffle`` == True, this multilabel implementation\n",
    "        always uses the random_state since the iterative stratification\n",
    "        algorithm breaks ties randomly.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> mskf = MultilabelStratifiedKFold(n_splits=2, random_state=0)\n",
    "    >>> mskf.get_n_splits(X, y)\n",
    "    2\n",
    "    >>> print(mskf)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    MultilabelStratifiedKFold(n_splits=2, random_state=0, shuffle=False)\n",
    "    >>> for train_index, test_index in mskf.split(X, y):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    Notes\n",
    "    -----\n",
    "    Train and test sizes may be slightly different in each fold.\n",
    "    See also\n",
    "    --------\n",
    "    RepeatedMultilabelStratifiedKFold: Repeats Multilabel Stratified K-Fold\n",
    "    n times.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=3, *, shuffle=False, random_state=None):\n",
    "        super(MultilabelStratifiedKFold, self).__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def _make_test_folds(self, X, y):\n",
    "        y = np.asarray(y, dtype=bool)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "\n",
    "        if type_of_target_y != 'multilabel-indicator':\n",
    "            raise ValueError(\n",
    "                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(type_of_target_y))\n",
    "\n",
    "        num_samples = y.shape[0]\n",
    "\n",
    "        rng = check_random_state(self.random_state)\n",
    "        indices = np.arange(num_samples)\n",
    "\n",
    "        if self.shuffle:\n",
    "            rng.shuffle(indices)\n",
    "            y = y[indices]\n",
    "\n",
    "        r = np.asarray([1 / self.n_splits] * self.n_splits)\n",
    "\n",
    "        test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n",
    "\n",
    "        return test_folds[np.argsort(indices)]\n",
    "\n",
    "    def _iter_test_masks(self, X=None, y=None, groups=None):\n",
    "        test_folds = self._make_test_folds(X, y)\n",
    "        for i in range(self.n_splits):\n",
    "            yield test_folds == i\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "            Note that providing ``y`` is sufficient to generate the splits and\n",
    "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
    "            ``X`` instead of actual training data.\n",
    "        y : array-like, shape (n_samples, n_labels)\n",
    "            The target variable for supervised learning problems.\n",
    "            Multilabel stratification is done based on the y labels.\n",
    "        groups : object\n",
    "            Always ignored, exists for compatibility.\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        Notes\n",
    "        -----\n",
    "        Randomized CV splitters may return different results for each call of\n",
    "        split. You can make the results identical by setting ``random_state``\n",
    "        to an integer.\n",
    "        \"\"\"\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        return super(MultilabelStratifiedKFold, self).split(X, y, groups)\n",
    "\n",
    "\n",
    "class RepeatedMultilabelStratifiedKFold(_RepeatedSplits):\n",
    "    \"\"\"Repeated Multilabel Stratified K-Fold cross validator.\n",
    "    Repeats Mulilabel Stratified K-Fold n times with different randomization\n",
    "    in each repetition.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of folds. Must be at least 2.\n",
    "    n_repeats : int, default=10\n",
    "        Number of times cross-validator needs to be repeated.\n",
    "    random_state : None, int or RandomState, default=None\n",
    "        Random state to be used to generate random state for each\n",
    "        repetition as well as randomly breaking ties within the iterative\n",
    "        stratification algorithm.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import RepeatedMultilabelStratifiedKFold\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> rmskf = RepeatedMultilabelStratifiedKFold(n_splits=2, n_repeats=2,\n",
    "    ...     random_state=0)\n",
    "    >>> for train_index, test_index in rmskf.split(X, y):\n",
    "    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...     X_train, X_test = X[train_index], X[test_index]\n",
    "    ...     y_train, y_test = y[train_index], y[test_index]\n",
    "    ...\n",
    "    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    TRAIN: [0 1 4 5] TEST: [2 3 6 7]\n",
    "    TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n",
    "    See also\n",
    "    --------\n",
    "    RepeatedStratifiedKFold: Repeats (Non-multilabel) Stratified K-Fold\n",
    "    n times.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits=5, *, n_repeats=10, random_state=None):\n",
    "        super(RepeatedMultilabelStratifiedKFold, self).__init__(\n",
    "            MultilabelStratifiedKFold, n_repeats=n_repeats, random_state=random_state,\n",
    "            n_splits=n_splits)\n",
    "\n",
    "\n",
    "class MultilabelStratifiedShuffleSplit(BaseShuffleSplit):\n",
    "    \"\"\"Multilabel Stratified ShuffleSplit cross-validator\n",
    "    Provides train/test indices to split data into train/test sets.\n",
    "    This cross-validation object is a merge of MultilabelStratifiedKFold and\n",
    "    ShuffleSplit, which returns stratified randomized folds for multilabel\n",
    "    data. The folds are made by preserving the percentage of each label.\n",
    "    Note: like the ShuffleSplit strategy, multilabel stratified random splits\n",
    "    do not guarantee that all folds will be different, although this is\n",
    "    still very likely for sizeable datasets.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default 10\n",
    "        Number of re-shuffling & splitting iterations.\n",
    "    test_size : float, int, None, optional\n",
    "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
    "        of the dataset to include in the test split. If int, represents the\n",
    "        absolute number of test samples. If None, the value is set to the\n",
    "        complement of the train size. By default, the value is set to 0.1.\n",
    "        The default will change in version 0.21. It will remain 0.1 only\n",
    "        if ``train_size`` is unspecified, otherwise it will complement\n",
    "        the specified ``train_size``.\n",
    "    train_size : float, int, or None, default is None\n",
    "        If float, should be between 0.0 and 1.0 and represent the\n",
    "        proportion of the dataset to include in the train split. If\n",
    "        int, represents the absolute number of train samples. If None,\n",
    "        the value is automatically set to the complement of the test size.\n",
    "    random_state : int, RandomState instance or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`. Unlike StratifiedShuffleSplit that only uses\n",
    "        random_state when ``shuffle`` == True, this multilabel implementation\n",
    "        always uses the random_state since the iterative stratification\n",
    "        algorithm breaks ties randomly.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> msss = MultilabelStratifiedShuffleSplit(n_splits=3, test_size=0.5,\n",
    "    ...    random_state=0)\n",
    "    >>> msss.get_n_splits(X, y)\n",
    "    3\n",
    "    >>> print(mss)       # doctest: +ELLIPSIS\n",
    "    MultilabelStratifiedShuffleSplit(n_splits=3, random_state=0, test_size=0.5,\n",
    "                                     train_size=None)\n",
    "    >>> for train_index, test_index in msss.split(X, y):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n",
    "    TRAIN: [1 2 5 6] TEST: [0 3 4 7]\n",
    "    Notes\n",
    "    -----\n",
    "    Train and test sizes may be slightly different from desired due to the\n",
    "    preference of stratification over perfectly sized folds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=10, *, test_size=\"default\", train_size=None,\n",
    "                 random_state=None):\n",
    "        super(MultilabelStratifiedShuffleSplit, self).__init__(\n",
    "            n_splits=n_splits, test_size=test_size, train_size=train_size, random_state=random_state)\n",
    "\n",
    "    def _iter_indices(self, X, y, groups=None):\n",
    "        n_samples = _num_samples(X)\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        y = np.asarray(y, dtype=bool)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "\n",
    "        if type_of_target_y != 'multilabel-indicator':\n",
    "            raise ValueError(\n",
    "                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(\n",
    "                    type_of_target_y))\n",
    "\n",
    "        n_train, n_test = _validate_shuffle_split(n_samples, self.test_size,\n",
    "                                                  self.train_size)\n",
    "\n",
    "        n_samples = y.shape[0]\n",
    "        rng = check_random_state(self.random_state)\n",
    "        y_orig = y.copy()\n",
    "\n",
    "        r = np.array([n_train, n_test]) / (n_train + n_test)\n",
    "\n",
    "        for _ in range(self.n_splits):\n",
    "            indices = np.arange(n_samples)\n",
    "            rng.shuffle(indices)\n",
    "            y = y_orig[indices]\n",
    "\n",
    "            test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n",
    "\n",
    "            test_idx = test_folds[np.argsort(indices)] == 1\n",
    "            test = np.where(test_idx)[0]\n",
    "            train = np.where(~test_idx)[0]\n",
    "\n",
    "            yield train, test\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "            Note that providing ``y`` is sufficient to generate the splits and\n",
    "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
    "            ``X`` instead of actual training data.\n",
    "        y : array-like, shape (n_samples, n_labels)\n",
    "            The target variable for supervised learning problems.\n",
    "            Multilabel stratification is done based on the y labels.\n",
    "        groups : object\n",
    "            Always ignored, exists for compatibility.\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        Notes\n",
    "        -----\n",
    "        Randomized CV splitters may return different results for each call of\n",
    "        split. You can make the results identical by setting ``random_state``\n",
    "        to an integer.\n",
    "        \"\"\"\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        return super(MultilabelStratifiedShuffleSplit, self).split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coef_significance(X, Y): \n",
    "    \"\"\"\n",
    "    Функция для оценки статистической значимость коэффициентов линейной регрессии\n",
    "\n",
    "    Параметры:\n",
    "        X - DataFrame - данные, содержащие несколько объектов с признаками\n",
    "        Y - array - целевая метрика для объектов из X\n",
    "\n",
    "    Выход:\n",
    "        table - DataFrame - таблица со значениями p-value, относительно которых можно делать вывод о статистической значимости коэффициента при каждом признаке в X.\n",
    "        lin_reg - statsmodels.OLS - обученная модель регрессии\n",
    "    \"\"\"\n",
    "    X_train = sm.tools.tools.add_constant(X.values.astype(np.float64), prepend=True, has_constant='skip')\n",
    "    \n",
    "    Y_train = Y\n",
    "\n",
    "    lin_reg = sm.OLS(Y_train, X_train).fit()\n",
    "    summary = lin_reg.summary().tables[1]\n",
    "    table = pd.read_html(summary.as_html(), header=0, index_col=0)[0]\n",
    "    return table, lin_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pval(pval):\n",
    "    \"\"\"\n",
    "    Функция для автоматической проверки p-value на статистическую значимость\n",
    "\n",
    "    Параметры:\n",
    "        pval - float - значение p-value\n",
    "    \"\"\"  \n",
    "    if pval <= 0.05:\n",
    "        print(f'p-val: {pval}\\nСтат. значимая разница (отвергли нулевую гипотезу о равенстве средних)')\n",
    "    else:\n",
    "        print(f'p-val: {pval}\\nСтатзначимой разницы нет')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(x, y, randomized=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Функция для проведения T-testa в двух модификациях: с обычной и с рандомизированной T-статистикой.\n",
    "\n",
    "    Параметры:\n",
    "        x - array - значение целевой метрики в тестовой группе\n",
    "        y - array - значение целевой метрики в контрольной группе\n",
    "        randomized - bool - индикатор того, какой тест проводить (рандомизированный - 1, стандартный - 0)\n",
    "        verbose - bool - печатать ли вспомогательную информацию\n",
    "        \n",
    "    Выход:\n",
    "         полученное в T-тесте p-value (float)\n",
    "    \"\"\" \n",
    "    n_x = x.shape[0]\n",
    "    n_y = y.shape[0]\n",
    "    \n",
    "    s_x = np.var(x, ddof=1)\n",
    "    s_y = np.var(y, ddof=1)\n",
    "    \n",
    "    if randomized:\n",
    "        b0 = n_x ** 0.75\n",
    "        b1 = n_y ** 0.75\n",
    "        \n",
    "        dof =  (s_x / n_x + s_y / n_y) ** 2 / ((s_x / n_x) ** 2 / (n_x - 1) + (s_y / n_y) ** 2 / (n_y - 1))\n",
    "        \n",
    "        \n",
    "        theta_x = np.append(np.tile(np.array([1, np.sqrt(2), 1, np.sqrt(2)]), math.ceil(b0)),\\\n",
    "                   np.tile(np.array([1, np.sqrt(2), -1, -np.sqrt(2)]), n_x // 4 + 1))\n",
    "        \n",
    "        theta_x = theta_x[:n_x]\n",
    "\n",
    "        theta_y = np.append(np.tile(np.array([1, np.sqrt(2), 1, np.sqrt(2)]), math.ceil(b1)),\\\n",
    "                   np.tile(np.array([1, np.sqrt(2), -1, -np.sqrt(2)]), n_y // 4 + 1))\n",
    "        \n",
    "        theta_y = theta_y[:n_y]\n",
    "\n",
    "        t_val = (theta_x @ x - theta_y @ y) / np.sqrt(s_x * np.sum(theta_x ** 2) + s_y * np.sum(theta_y ** 2))\n",
    "        p = 2*(stats.t.cdf(-abs(t_val), dof))\n",
    "        \n",
    "    else: \n",
    "        t_val, p = stats.ttest_ind(x, y, equal_var=False) \n",
    "        \n",
    "    if verbose:\n",
    "        check_pval(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка датасета и генерация подвыборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Для скачивания датасета раскомментировать следующий код\n",
    "#!wget http://go.criteo.net/criteo-research-uplift-v2.1.csv.gz\n",
    "#!gzip -d ./criteo-research-uplift-v2.1.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае, если у вас не работает утилита wget - датасет нужно скачать вручную по ссылке выше и распаковать из архива в .csv файл с названием 'criteo-research-uplift-v2.1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#считывание датасета\n",
    "#inp_df = pd.read_csv('criteo-research-uplift-v2.1.csv')\n",
    "\n",
    "inp_df = pd.read_csv('criteo-uplift-v2.1.csv')\n",
    "\n",
    "features = ['f{}'.format(n) for n in range(12)]\n",
    "inp_df[features] = normalize(inp_df[features], axis=0, norm='l2')\n",
    "df = inp_df \n",
    "\n",
    "X = features\n",
    "y = 'visit'\n",
    "t = 'treatment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['f1', 'f3', 'f4', 'f5', 'f6', 'f8', 'f9', 'f11']\n",
    "noncat_features = list(df.columns.difference(cat_features + [y,t,'conversion', 'exposure']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value по всем данных: 0.0\n"
     ]
    }
   ],
   "source": [
    "t, p = stats.ttest_ind(df.loc[df['treatment'] == 1, 'visit'], df.loc[df['treatment'] == 0, 'visit'], equal_var=False, random_state=3)\n",
    "print(f'p-value по всем данных: {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация стратифицированной подвыборки меньшего размера\n",
    "\n",
    "В данной подвыборке с помощью стандартного Т-теста нулевая гипотеза \n",
    "$$\\mathcal{H_0}: \\mu_1 = \\mu_2\\, ,$$\n",
    "не отвергается при истинности альтернативной\n",
    "$$\\mathcal{H_1}: \\mu_1 \\neq \\mu_2\\, ,$$\n",
    "\n",
    "где $\\mu_1$ и $\\mu_2$ - математические ожидания в тестовой и контрольной выборках. Таким образом, размеры сгенерированных подвыборок недостаточны для того, чтобы обнаружить величину эффекта, равную $\\mu_1 - \\mu_2$.\n",
    "\n",
    "Стратифицированная подвыборка генерируется с помощью MultilabelStratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f0', 'f2', 'f8', 'f9', 'visit']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['f0', 'f2', 'f8', 'f9', 'visit']\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_control = df.loc[df['treatment'] == 0]\n",
    "all_treatment = df.loc[df['treatment'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.666672389299249"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = all_treatment.shape[0] / all_control.shape[0]\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.4'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/1550503900.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Открытие pkl файла\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"control_sample.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Вывод данных\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Открытие pkl файла\n",
    "with open(\"control_sample.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Вывод данных\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/3255128474.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcontrol_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"control_sample.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[1;31m#  \"No module named 'pandas.core.sparse.series'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;31m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;31m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUnpicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STACK_GLOBAL requires str\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSTACK_GLOBAL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_stack_global\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_class_locations_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1579\u001b[0m         \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1581\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1582\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1583\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[1;34m(obj, name)\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             raise AttributeError(\"Can't get attribute {!r} on {!r}\"\n\u001b[0m\u001b[0;32m    332\u001b[0m                                  .format(name, obj)) from None\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>"
     ]
    }
   ],
   "source": [
    "control_sample = pd.read_pickle(\"control_sample.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/1112598170.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcontrol_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./saved_variables/control_sample.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtreatment_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./saved_variables/treatment_sample.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[1;31m#  \"No module named 'pandas.core.sparse.series'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;31m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;31m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUnpicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STACK_GLOBAL requires str\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSTACK_GLOBAL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_stack_global\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_class_locations_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1579\u001b[0m         \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1581\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1582\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1583\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[1;34m(obj, name)\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             raise AttributeError(\"Can't get attribute {!r} on {!r}\"\n\u001b[0m\u001b[0;32m    332\u001b[0m                                  .format(name, obj)) from None\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>"
     ]
    }
   ],
   "source": [
    "control_sample = pd.read_pickle(\"./saved_variables/control_sample.pkl\")  \n",
    "treatment_sample = pd.read_pickle(\"./saved_variables/treatment_sample.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В данной секции стратифицированным образом отбирается заданное число подвыборок размера 0.0005 от всего датасета. Если вы не хотите ждать, пока они будут сгенерированы, пропустите данную секцию и загрузите готовые данные из ячейки выше. В противном случае - раскомментируйте код ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size_control = 0.0005\n",
    "#scale = all_treatment.shape[0] / all_control.shape[0]\n",
    "#size_treatment = int(scale * size_control * all_control.shape[0]) # scale * control_size = scale * 0.002 * all_control.shape[0]\n",
    "\n",
    "#msss_control = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=size_control, random_state=0)\n",
    "#msss_treatment = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=size_treatment, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trval_i, control_sample_i = next(msss_control.split(all_control.values, all_control.loc[:, columns].values))\n",
    "#trval_i, treatment_sample_i = next(msss_treatment.split(all_treatment.values, all_treatment.loc[:, columns].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control_sample = all_control.iloc[control_sample_i]\n",
    "#treatment_sample = all_treatment.iloc[treatment_sample_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(control_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"treatment: {treatment_sample.shape[0]}, control: {control_sample.shape[0]}, frac: {treatment_sample.shape[0] / control_sample.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control_size = 0.0005\n",
    "#stats.ttest_ind(treatment_sample['visit'], control_sample['visit'], equal_var=False, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Дисперсия в подвыборках: контроль {control_sample['visit'].var()}, тест {treatment_sample['visit'].var()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация исторического контекста\n",
    "\n",
    "Генерация стратифицированной подвыборки, которая соответствует предэкспериментальному периоду.\n",
    "\n",
    "Стратифицированная подвыборка генерируется с помощью MultilabelStratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/3856293642.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# # Код ниже в этой секции можно не запускать, а скачать сохраненную подвыборку\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcontrol_sample_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved_variables/control_sample_hist.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtreatment_sample_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved_variables/treatment_sample_hist.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[1;31m#  \"No module named 'pandas.core.sparse.series'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;31m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;31m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUnpicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STACK_GLOBAL requires str\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSTACK_GLOBAL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_stack_global\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_class_locations_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1579\u001b[0m         \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1581\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1582\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1583\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[1;34m(obj, name)\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             raise AttributeError(\"Can't get attribute {!r} on {!r}\"\n\u001b[0m\u001b[0;32m    332\u001b[0m                                  .format(name, obj)) from None\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>"
     ]
    }
   ],
   "source": [
    "# # Код ниже в этой секции можно не запускать, а скачать сохраненную подвыборку\n",
    "control_sample_hist = pd.read_pickle(\"saved_variables/control_sample_hist.pkl\")  \n",
    "treatment_sample_hist = pd.read_pickle(\"saved_variables/treatment_sample_hist.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_control_for_hist = df.loc[(df['treatment'] == 0) & (~df.index.isin(control_sample.index))]\n",
    "#all_treatment_for_hist = df.loc[(df['treatment'] == 1) & (~df.index.isin(treatment_sample.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size_control = 0.0005\n",
    "#scale = all_treatment_for_hist.shape[0] / all_control_for_hist.shape[0]\n",
    "#size_treatment = int(scale * size_control * all_control_for_hist.shape[0]) # scale * control_size = scale * 0.002 * all_control.shape[0]\n",
    "\n",
    "#msss_control = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=size_control, random_state=2)\n",
    "#msss_treatment = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=size_treatment, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trval_i, control_sample_hist_i = next(msss_control.split(all_control_for_hist.values, all_control_for_hist.loc[:, columns].values))\n",
    "#trval_i, treatment_sample_hist_i = next(msss_treatment.split(all_treatment_for_hist.values, all_treatment_for_hist.loc[:, columns].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control_sample_hist = all_control_for_hist.iloc[control_sample_hist_i]\n",
    "#treatment_sample_hist = all_treatment_for_hist.iloc[treatment_sample_hist_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"treatment: {treatment_sample_hist.shape[0]}, control: {control_sample_hist.shape[0]}, frac: {treatment_sample_hist.shape[0] / control_sample_hist.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация подвыборки с увеличивающимся размером\n",
    "\n",
    "Генерация стратифицированных подвыборок размерами от 420 до 4200 с шагом 420 для эксперимента, описанного в разделе 3.4.1 отчета о НИР.\n",
    "\n",
    "Стратифицированные подвыборки генерируются с помощью MultilabelStratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'control_sample_hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/1847550441.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_control\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'treatment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_sample_hist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mall_treatment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'treatment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtreatment_sample_hist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'control_sample_hist' is not defined"
     ]
    }
   ],
   "source": [
    "all_control = df.loc[(df['treatment'] == 0) & (~df.index.isin(control_sample_hist.index))]\n",
    "all_treatment = df.loc[(df['treatment'] == 1) & (~df.index.isin(treatment_sample_hist.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/3017467820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtreatment_indexes_big\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcontrol_indexes_big\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"saved_variables/control_data_split_35e-5_{i}.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtreatment_indexes_big\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"saved_variables/treatment_data_split_35e-5_{i}.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[1;31m#  \"No module named 'pandas.core.sparse.series'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;31m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;31m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUnpicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STACK_GLOBAL requires str\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSTACK_GLOBAL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_stack_global\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_class_locations_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1579\u001b[0m         \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1581\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1582\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1583\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[1;34m(obj, name)\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             raise AttributeError(\"Can't get attribute {!r} on {!r}\"\n\u001b[0m\u001b[0;32m    332\u001b[0m                                  .format(name, obj)) from None\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>"
     ]
    }
   ],
   "source": [
    "# ## Код ниже в этой секции можно не запускать, а скачать сохраненную подвыборку из папки saved_variables\n",
    "n_splits = 10\n",
    "#Большие размеры выборок для теста и контроля\n",
    "control_indexes_big = []\n",
    "treatment_indexes_big = []\n",
    "for i in range(n_splits):\n",
    "    control_indexes_big.append(pd.read_pickle(f\"saved_variables/control_data_split_35e-5_{i}.pkl\")) \n",
    "    treatment_indexes_big.append(pd.read_pickle(f\"saved_variables/treatment_data_split_35e-5_{i}.pkl\"))\n",
    "\n",
    "#Маленькие размеры выборок для теста и контроля\n",
    "control_indexes_small = []\n",
    "treatment_indexes_small = []\n",
    "for i in range(n_splits):\n",
    "    control_indexes_small.append(pd.read_pickle(f\"saved_variables/control_data_split_2e-4_{i}.pkl\"))\n",
    "    treatment_indexes_small.append(pd.read_pickle(f\"saved_variables/treatment_data_split_2e-4_{i}.pkl\")) \n",
    "\n",
    "all_in_slit_control = []\n",
    "all_in_slit_treatment = []\n",
    "\n",
    "for i in tqdm(range(0, len(control_indexes_small))):\n",
    "    all_in_slit_control.extend(control_indexes_small[i].index)\n",
    "    all_in_slit_treatment.extend(treatment_indexes_small[i].index)\n",
    "    \n",
    "for i in tqdm(range(0, len(control_indexes_big))):\n",
    "    all_in_slit_control.extend(control_indexes_big[i].index)\n",
    "    all_in_slit_treatment.extend(treatment_indexes_big[i].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size_control = 0.00035\n",
    "#n_splits = 10\n",
    "\n",
    "#all_control.shape[0] * size_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size_control = 0.00035\n",
    "#scale = all_treatment.shape[0] / all_control.shape[0]\n",
    "#size_treatment = int(scale * size_control * all_control.shape[0]) # scale * control_size = scale * 0.002 * all_control.shape[0]\n",
    "\n",
    "#msss_control = MultilabelStratifiedShuffleSplit(n_splits=10, test_size=size_control, random_state=3)\n",
    "#msss_treatment = MultilabelStratifiedShuffleSplit(n_splits=10, test_size=size_treatment, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control_generator = msss_control.split(all_control.values, all_control.loc[:, columns].values)\n",
    "#treatment_generator = msss_treatment.split(all_treatment.values, all_treatment.loc[:, columns].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "#control_indexes = list(control_generator)\n",
    "#treatment_indexes = list(treatment_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_control = []\n",
    "#data_treatment = []\n",
    "\n",
    "#for i in tqdm(range(0, len(control_indexes))):\n",
    "#    data_control.append(all_control.iloc[control_indexes[i][1]])\n",
    "#    data_treatment.append(all_treatment.iloc[treatment_indexes[i][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Методы снижения дисперсии при помощи контрольных переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод CUPED из раздела 3.1 отчета о НИР"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Deng, Y. Xu, R. Kohavi, T. Walker. \"Improving the sensitivity of online controlled experiments by utilizing pre-experiment data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_with_cuped(control, experimental, control_hist, experimental_hist, columns, pipeline=False, encoder=\"OHE\", verbose=False):\n",
    "    \"\"\"\n",
    "    Применение метода CUPED к контрольной и тестовой выборкам.\n",
    "        \n",
    "\n",
    "    Параметры:\n",
    "        control - DataFrame - объекты, относящиеся к контрольной группе\n",
    "        experimental - DataFrame - объекты, относящиеся к контрольной группе\n",
    "        control_hist - DataFrame - объекты, относящиеся к историческим данным\n",
    "        experimental_hist - DataFrame - объекты, относящиеся к историческим данным\n",
    "        columns - list[str] - имена признаков, используемые в качестве контрольных переменных\n",
    "        pipeline - bool - индикатор дополнительного преобразования признаков\n",
    "        encoder - str - какой энкодер использовать, если pipeline=True\n",
    "        verbose - bool - печатать ли впомогательную информацию \n",
    "    Выход:\n",
    "        p-value - float - значение p-value до и после применения CUPED\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Control size: {control.shape[0]}, Experimental size: {experimental.shape[0]}\")\n",
    "    #для обучения контрольной переменной используется предыстория для контрольной и экспериментальной групп\n",
    "    X = pd.concat((control_hist, experimental_hist), axis=0).sample(frac=1)\n",
    "    #выделим целевую переменную\n",
    "    Y = X['visit']\n",
    "    #выделим значимые признаки\n",
    "    X = X[columns]\n",
    "    \n",
    "    categorical_columns = list(set(cat_features).intersection(set(columns)))\n",
    "    numerical_columns = list(set(noncat_features).intersection(set(columns)))\n",
    "\n",
    "\n",
    "    # Применение пайплайна обработки категориальных признаков (если pipeline=True) и обучение модели\n",
    "    \n",
    "    if pipeline:\n",
    "        #центрируем числовые признаки\n",
    "        means = np.mean(X[numerical_columns])\n",
    "        X[numerical_columns] = X[numerical_columns] - means\n",
    "        #one-hot-encoding для категориальных признаков (по умолчанию)\n",
    "        if encoder == 'OHE':\n",
    "            categorical_encoder = OneHotEncoder(\n",
    "            handle_unknown=\"ignore\"\n",
    "            )\n",
    "        else:  \n",
    "            categorical_encoder = OrdinalEncoder(\n",
    "            handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
    "            )\n",
    "            \n",
    "        numerical_pipe = SimpleImputer(strategy=\"mean\")\n",
    "        #применить заданную предобработку к \n",
    "        preprocessing = ColumnTransformer(\n",
    "            [\n",
    "                (\"cat\", categorical_encoder, categorical_columns),\n",
    "                (\"num\", numerical_pipe, numerical_columns),\n",
    "            ],\n",
    "            #раскомментировать строчку ниже в более новых версиях sklearn\n",
    "            #verbose_feature_names_out=False,\n",
    "        )\n",
    "        #общий пайплайн из предобработки и линейной регрессии\n",
    "        reg = Pipeline(\n",
    "            [\n",
    "                (\"preprocess\", preprocessing),\n",
    "                (\"regressor\", linear_model.LinearRegression()),\n",
    "            ]\n",
    "        )\n",
    "        #фит на данных\n",
    "        reg.fit(X, Y)\n",
    "        #центрируем признаки в контрольной и тестовых группах на исторические средние\n",
    "        c = control[columns]\n",
    "        e = experimental[columns]\n",
    "        c[numerical_columns] = c[numerical_columns] - means\n",
    "        e[numerical_columns] = e[numerical_columns] - means\n",
    "    else:\n",
    "        #просто центрируем все признаки и обучаем линейную регрессию\n",
    "        means = np.mean(X)\n",
    "        X = X - means\n",
    "\n",
    "        reg = Pipeline(\n",
    "            [\n",
    "                (\"regressor\", linear_model.LinearRegression()),\n",
    "            ]\n",
    "        )\n",
    "        reg.fit(X, Y)\n",
    "        #центрируем признаки в контрольной и тестовых группах на исторические средние\n",
    "        c = control[columns] - means\n",
    "        e = experimental[columns] - means\n",
    "\n",
    "    y_c = control['visit']\n",
    "    y_e = experimental['visit']\n",
    "    # Изменение целевой переменной\n",
    "    control_cuped = y_c - reg.predict(c) + reg.predict(c).mean()\n",
    "    experimental_cuped = y_e - reg.predict(e) + reg.predict(e).mean()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"control var new: {np.var(control_cuped)}, var old: {np.var(y_c)}\")\n",
    "        print(f\"exper var new: {np.var(experimental_cuped)}, var old: {np.var(y_e)}\")\n",
    "\n",
    "        print(f\"Mean diff\\nold: {y_c.mean() - y_e.mean()}, new: {control_cuped.mean() - experimental_cuped.mean()}\\n\")\n",
    "    #p-значения для (нерандомизированного) t-теста до и после применения CUPED\n",
    "    p_before = ttest(y_c, y_e)\n",
    "    p_after = ttest(control_cuped, experimental_cuped)\n",
    "    return p_before, p_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод CUPAC из раздела 3.2 отчета о НИР"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Poyarkov, A. Drutsa, A. Khalyavin, G. Gusev, P. Serdyukov. \"Boosted decision tree regression adjustment for variance reduction in online controlled experiments.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_with_cupac(control, experimental, control_hist, experimental_hist, columns, pipeline=False, encoder='OHE', verbose=False):\n",
    "    \"\"\"\n",
    "    Применение метода CUPAC к контрольной и тестовой выборкам\n",
    "\n",
    "    Параметры:\n",
    "        control - DataFrame - объекты, относящиеся к контрольной группе\n",
    "        experimental - DataFrame - объекты, относящиеся к контрольной группе\n",
    "        control_hist - DataFrame - объекты, относящиеся к историческим данным\n",
    "        experimental_hist - DataFrame - объекты, относящиеся к историческим данным\n",
    "        columns - list[str] - имена признаков, используемые в качестве контрольных переменных\n",
    "        pipeline - bool - индикатор дополнительного преобразования признаков\n",
    "        encoder - str - какой энкодер использовать, если pipeline=True\n",
    "        verbose - bool - печатать ли впомогательную информацию \n",
    "    Выход:\n",
    "        p-value - float - значение p-value до и после применения CUPAC\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Control size: {control.shape[0]}, Experimental size: {experimental.shape[0]}\")\n",
    "\n",
    "    X = pd.concat((control_hist, experimental_hist), axis=0).sample(frac=1)\n",
    "\n",
    "\n",
    "    Y = X['visit']\n",
    "    X = X[columns]\n",
    "    \n",
    "    categorical_columns = list(set(cat_features).intersection(set(columns)))\n",
    "    numerical_columns = list(set(noncat_features).intersection(set(columns)))\n",
    "    \n",
    "    # Применение пайплайна обработки категориальных признаков (если pipeline=True) и обучение модели\n",
    "    if pipeline:\n",
    "        \n",
    "        means = np.mean(X[numerical_columns])\n",
    "        X[numerical_columns] = X[numerical_columns] - means\n",
    "        \n",
    "        if encoder == 'OHE':\n",
    "            categorical_encoder = OneHotEncoder(\n",
    "            handle_unknown=\"ignore\"\n",
    "            )\n",
    "        else:  \n",
    "            categorical_encoder = OrdinalEncoder(\n",
    "            handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
    "            )\n",
    "            \n",
    "        numerical_pipe = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "        preprocessing = ColumnTransformer(\n",
    "            [\n",
    "                (\"cat\", categorical_encoder, categorical_columns),\n",
    "                (\"num\", numerical_pipe, numerical_columns),\n",
    "            ],\n",
    "            #раскомментировать строчку ниже в более новых версиях sklearn\n",
    "            #verbose_feature_names_out=False,\n",
    "        )\n",
    "\n",
    "        reg = Pipeline(\n",
    "            [\n",
    "                (\"preprocess\", preprocessing),\n",
    "                (\"regressor\", GradientBoostingRegressor(n_estimators=200, learning_rate=0.01, min_samples_split=2, min_samples_leaf=1, max_depth=3, random_state=2)),\n",
    "            ]\n",
    "        )\n",
    "        reg.fit(X, Y)\n",
    "        \n",
    "        c = control[columns]\n",
    "        e = experimental[columns]\n",
    "        c[numerical_columns] = c[numerical_columns] - means\n",
    "        e[numerical_columns] = e[numerical_columns] - means\n",
    "    else:\n",
    "        means = np.mean(X)\n",
    "        X = X - means\n",
    "        \n",
    "        reg = Pipeline(\n",
    "            [\n",
    "                (\"regressor\", GradientBoostingRegressor(n_estimators=200, learning_rate=0.01, min_samples_split=2, min_samples_leaf=1, max_depth=3, random_state=2)),\n",
    "            ]\n",
    "        )\n",
    "        reg.fit(X, Y)\n",
    "    \n",
    "        c = control[columns] - means\n",
    "        e = experimental[columns] - means\n",
    "    \n",
    "\n",
    "\n",
    "    y_c = control['visit']\n",
    "    y_e = experimental['visit']\n",
    "\n",
    "    \n",
    "    # Изменение целевой переменной\n",
    "    control_cuped = y_c - reg.predict(c)  + reg.predict(c).mean()\n",
    "    experimental_cuped = y_e - reg.predict(e) + reg.predict(e).mean()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"control var new: {np.var(control_cuped)}, var old: {np.var(y_c)}\")\n",
    "        print(f\"exper var new: {np.var(experimental_cuped)}, var old: {np.var(y_e)}\")\n",
    "\n",
    "        print(f\"Mean diff\\nold: {y_c.mean() - y_e.mean()}, new: {control_cuped.mean() - experimental_cuped.mean()}\\n\")\n",
    "    \n",
    "    \n",
    "    p_before = ttest(y_c, y_e)\n",
    "    \n",
    "    p_after = ttest(control_cuped, experimental_cuped)\n",
    "    return p_before, p_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод ML-rate из раздела 3.3 отчета о НИР"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y. Guo, D. Coey, M. Konutgan, W. Li, C. Schoener, M. Goldman. \"Machine learning for variance reduction in online experiments.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_with_ml_rate(control, experimental, control_hist, experimental_hist, columns, verbose=False, aa=False):\n",
    "    \"\"\"\n",
    "    Применение метода Ml-rate к контрольной и тестовой выборкам\n",
    "\n",
    "    Параметры:\n",
    "        control - DataFrame - объекты, относящиеся к контрольной группе\n",
    "        experimental - DataFrame - объекты, относящиеся к контрольной группе\n",
    "        control_hist - DataFrame - объекты, относящиеся к историческим данным\n",
    "        experimental_hist - DataFrame - объекты, относящиеся к историческим данным\n",
    "        columns - list[str] - имена признаков, используемые в качестве контрольных переменных\n",
    "        verbose - bool - печатать ли впомогательную информацию \n",
    "        aa - bool - проводится ли AA тест\n",
    "    Выход:\n",
    "        p-value - float - значение p-value до и после применения Ml-rate\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Control size: {control.shape[0]}, Experimental size: {experimental.shape[0]}\")\n",
    "    \n",
    "    if aa:\n",
    "        experimental['treatment'] = 1\n",
    "        \n",
    "    Z = pd.concat((control, experimental, control_hist, experimental_hist), axis=0).sample(frac=1)\n",
    "    means = np.mean(Z[columns])\n",
    "\n",
    "    Y = Z['visit']\n",
    "    X = Z[columns]\n",
    "    X = X - means.values\n",
    "    X = pd.concat((X, Z['treatment']), axis=1)\n",
    "    \n",
    "    # Обучение модели линейной регрессии\n",
    "    table_summary, model = get_coef_significance(sm.tools.tools.add_constant(X), Y)\n",
    "    p_after = table_summary.iloc[-1, :]['P>|t|']\n",
    "    \n",
    "    return p_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отбор признаков "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для метода CUPED были выбраны наиболее значимые признаки из датасета при обучении линейной регрессии.\n",
    "\n",
    "Для метода CUPAC - с помощью Permutation Feature Importance. Данный подход основан на том, что при изменении значений конкретного признака (путем случайной перестановки или перемешивания) и оценке влияния этого изменения на метрику качества модели можно определить, насколько важен этот признак для модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_regr_ordinal = ['f6', 'f8', 'f9', 'f0', 'f2']\n",
    "cols_boosting = ['f2', 'f0', 'f9', 'f10', 'f4', 'f7', 'f8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эксперимент с размером исторических данных из раздела 3.4.2 отчета о НИР"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graphics(before=None, after_cup=None, after_gb=None, p_after_reg=None, title='', alpha=0.05):\n",
    "    \"\"\"\n",
    "    Функция для отрисовки результатов работы методов\n",
    "\n",
    "    Параметры:\n",
    "        before - array - значения p-value для метода с использование изначальной целевой переменной\n",
    "        after_cup - array - значения p-value для метода с использование целевой переменной, модифицированной методов CUPED\n",
    "        after_gb - array - значения p-value для метода с использование целевой переменной, модифицированной методов CUPAC\n",
    "        after_reg - array - значения p-value для метода с использование целевой переменной, модифицированной методов Ml-rate\n",
    "        title - str - дополнительная над графиками\n",
    "        alpha - float - уровень значимости\n",
    "    \"\"\"\n",
    "    if len(title) != 0:\n",
    "        print('\\n', title, '\\n')\n",
    "        \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "    ax1.plot(shapes, [alpha] * len(shapes), color=\"red\", linestyle='dashed', label='alpha')\n",
    "    if not (before is None):\n",
    "        ax1.plot(shapes, before, marker='o', ms=5, label='Default')\n",
    "        ax2.plot(shapes, np.log(before), marker='o', ms=5, label='Default')\n",
    "    if not (after_cup is None):\n",
    "        ax1.plot(shapes, after_cup, marker='o', ms=5, label='CUPED')\n",
    "        ax2.plot(shapes, np.log(after_cup), marker='o', ms=5, label='CUPED')\n",
    "    if not (after_gb is None):\n",
    "        ax1.plot(shapes, after_gb, marker='o', ms=5, label='CUPAC')\n",
    "        ax2.plot(shapes, np.log(after_gb), marker='o', ms=5, label='CUPAC')\n",
    "    if not (p_after_reg is None):\n",
    "        ax1.plot(shapes, p_after_reg, marker='o', ms=5, label='Ml-rate')\n",
    "        ax2.plot(shapes, np.log(p_after_reg), marker='o', ms=5, label='Ml-rate')\n",
    "    ax1.set_xlabel('Размер контрольной выборки', fontsize=15)\n",
    "    ax1.set_ylabel('p-value', fontsize=15)\n",
    "#     ax1.set_title(f'Поведение p-value в зависимости от размера выборки', fontsize=15)\n",
    "\n",
    "    ax2.plot(shapes, [np.log(alpha)] * len(shapes), color=\"red\", linestyle='dashed', label='alpha')\n",
    "    ax2.set_xlabel('Размер контрольной выборки', fontsize=15)\n",
    "    ax2.set_ylabel('log p-value', fontsize=15)\n",
    "#     ax2.set_title(f'Поведение log p-value в зависимости от размера выборки',fontsize=15)\n",
    "\n",
    "    ax1.legend(fontsize='x-large')\n",
    "    ax2.legend(fontsize='x-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Очень маленький исторический контекст (см. раздел отчета 3.4.2 для более подробного описания постановки задач)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'control_indexes_small' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/2541598402.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_indexes_small\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mtest_control\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontrol_indexes_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtest_treatment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtreatment_indexes_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'control_indexes_small' is not defined"
     ]
    }
   ],
   "source": [
    "indexes_control = np.array([])\n",
    "indexes_treatment = np.array([])\n",
    "cols1 = cols_regr_ordinal\n",
    "cols2 = cols_boosting\n",
    "cols3 = ['f4', 'f11', 'f2']\n",
    "\n",
    "shapes = []\n",
    "\n",
    "before = []\n",
    "after_cup = []\n",
    "after_gb = []\n",
    "after_reg = []\n",
    "\n",
    "all_test_control = pd.DataFrame()\n",
    "all_test_treatment = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "for i in tqdm(range(0, len(control_indexes_small))):\n",
    "    test_control = control_indexes_small[i]\n",
    "    test_treatment = treatment_indexes_small[i]\n",
    "    \n",
    "    test_control = test_control[~np.isin(test_control.index, indexes_control)]\n",
    "    test_treatment = test_treatment[~np.isin(test_treatment.index, indexes_treatment)]\n",
    "\n",
    "    # Добавление элементов в выборку с прошлого шага\n",
    "    all_test_control = pd.concat((all_test_control, test_control), axis=0)\n",
    "    all_test_treatment = pd.concat((all_test_treatment, test_treatment), axis=0)\n",
    "    shapes.append(all_test_control.shape[0])\n",
    "    \n",
    "    indexes_control = np.append(indexes_control,  test_control.index)\n",
    "    indexes_treatment = np.append(indexes_treatment,  test_treatment.index)\n",
    "    \n",
    "    # Выбор исторического контекста\n",
    "    hist_c = control_sample_hist.sample(100, random_state=1)\n",
    "    hist_e = treatment_sample_hist.sample(100, random_state=1)\n",
    "    \n",
    "    # Запуск методов\n",
    "    p_bef, p_aft_cup = modify_with_cuped(all_test_control, all_test_treatment, hist_c, hist_e, cols1, True, encoder=\"Ord\", verbose=False)\n",
    "    p_bef, p_aft_gb = modify_with_cupac(all_test_control, all_test_treatment, hist_c, hist_e, cols2, False, verbose=False)\n",
    "    p_aft_reg = modify_with_ml_rate(all_test_control, all_test_treatment, hist_c, hist_e, cols3)\n",
    "    \n",
    "    \n",
    "    before.append(p_bef)\n",
    "    after_cup.append(p_aft_cup)\n",
    "    after_gb.append(p_aft_gb)\n",
    "    after_reg.append(p_aft_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'control_indexes_small' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/2520258834.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdraw_graphics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbefore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_cup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_gb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf'Маленькие фолды: {control_indexes_small[0].shape[0]}\\nМаленькая история: {hist_c.shape[0] + hist_e.shape[0]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'control_indexes_small' is not defined"
     ]
    }
   ],
   "source": [
    "draw_graphics(before, after_cup, after_gb, after_reg, title=f'Маленькие фолды: {control_indexes_small[0].shape[0]}\\nМаленькая история: {hist_c.shape[0] + hist_e.shape[0]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Маленький исторический контекст (см. раздел отчета 3.4.2 для более подробного описания постановки задач)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'control_indexes_small' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/2397247475.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_indexes_small\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mtest_control\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontrol_indexes_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtest_treatment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtreatment_indexes_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'control_indexes_small' is not defined"
     ]
    }
   ],
   "source": [
    "indexes_control = np.array([])\n",
    "indexes_treatment = np.array([])\n",
    "cols1 = cols_regr_ordinal\n",
    "cols2 = cols_boosting\n",
    "cols3 = ['f4', 'f11', 'f2']\n",
    "\n",
    "shapes = []\n",
    "\n",
    "before = []\n",
    "after_cup = []\n",
    "after_gb = []\n",
    "after_reg = []\n",
    "\n",
    "all_test_control = pd.DataFrame()\n",
    "all_test_treatment = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "for i in tqdm(range(0, len(control_indexes_small))):\n",
    "    test_control = control_indexes_small[i]\n",
    "    test_treatment = treatment_indexes_small[i]\n",
    "    \n",
    "    \n",
    "    test_control = test_control[~np.isin(test_control.index, indexes_control)]\n",
    "    test_treatment = test_treatment[~np.isin(test_treatment.index, indexes_treatment)]\n",
    "    \n",
    "    # Добавление элементов в выборку с прошлого шага\n",
    "    all_test_control = pd.concat((all_test_control, test_control), axis=0)\n",
    "    all_test_treatment = pd.concat((all_test_treatment, test_treatment), axis=0)\n",
    "    shapes.append(all_test_control.shape[0])\n",
    "    \n",
    "    indexes_control = np.append(indexes_control,  test_control.index)\n",
    "    indexes_treatment = np.append(indexes_treatment,  test_treatment.index)\n",
    "    \n",
    "    # Выбор исторического контекста\n",
    "    hist_c = control_sample_hist.sample(450, random_state=1)\n",
    "    hist_e = treatment_sample_hist.sample(int(scale * 450), random_state=1)\n",
    "    \n",
    "    # Запуск методов\n",
    "    p_bef, p_aft_cup = modify_with_cuped(all_test_control, all_test_treatment, hist_c, hist_e, cols1, True, encoder=\"Ord\", verbose=False)\n",
    "    p_bef, p_aft_gb = modify_with_cupac(all_test_control, all_test_treatment, hist_c, hist_e, cols2, False, verbose=False)\n",
    "    p_aft_reg = modify_with_ml_rate(all_test_control, all_test_treatment, hist_c, hist_e, cols3)\n",
    "\n",
    "    \n",
    "    before.append(p_bef)\n",
    "    after_cup.append(p_aft_cup)\n",
    "    after_gb.append(p_aft_gb)\n",
    "    after_reg.append(p_aft_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'control_indexes_small' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/2520258834.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdraw_graphics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbefore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_cup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_gb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf'Маленькие фолды: {control_indexes_small[0].shape[0]}\\nМаленькая история: {hist_c.shape[0] + hist_e.shape[0]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'control_indexes_small' is not defined"
     ]
    }
   ],
   "source": [
    "draw_graphics(before, after_cup, after_gb, after_reg, title=f'Маленькие фолды: {control_indexes_small[0].shape[0]}\\nМаленькая история: {hist_c.shape[0] + hist_e.shape[0]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Большой исторический контекст (см. раздел отчета 3.4.2 для более подробного описания постановки задач)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'control_indexes_small' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/406600697.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_indexes_small\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mtest_control\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontrol_indexes_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtest_treatment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtreatment_indexes_small\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'control_indexes_small' is not defined"
     ]
    }
   ],
   "source": [
    "indexes_control = np.array([])\n",
    "indexes_treatment = np.array([])\n",
    "cols1 = cols_regr_ordinal\n",
    "cols2 = cols_boosting\n",
    "cols3 = ['f4', 'f11', 'f2']\n",
    "\n",
    "shapes = []\n",
    "\n",
    "before = []\n",
    "after_cup = []\n",
    "after_gb = []\n",
    "after_reg = []\n",
    "\n",
    "all_test_control = pd.DataFrame()\n",
    "all_test_treatment = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "for i in tqdm(range(0, len(control_indexes_small))):\n",
    "    test_control = control_indexes_small[i]\n",
    "    test_treatment = treatment_indexes_small[i]\n",
    "    \n",
    "    test_control = test_control[~np.isin(test_control.index, indexes_control)]\n",
    "    test_treatment = test_treatment[~np.isin(test_treatment.index, indexes_treatment)]\n",
    "    \n",
    "    # Добавление элементов в выборку с прошлого шага\n",
    "    all_test_control = pd.concat((all_test_control, test_control), axis=0)\n",
    "    all_test_treatment = pd.concat((all_test_treatment, test_treatment), axis=0)\n",
    "    shapes.append(all_test_control.shape[0])\n",
    "    \n",
    "    indexes_control = np.append(indexes_control,  test_control.index)\n",
    "    indexes_treatment = np.append(indexes_treatment,  test_treatment.index)\n",
    "    \n",
    "    # Выбор исторического контекста\n",
    "    hist_c = control_sample_hist\n",
    "    hist_e = treatment_sample_hist\n",
    "    \n",
    "    # Запуск методов\n",
    "    p_bef, p_aft_cup = modify_with_cuped(all_test_control, all_test_treatment, hist_c, hist_e, cols1, True, encoder=\"Ord\", verbose=False)\n",
    "    p_bef, p_aft_gb = modify_with_cupac(all_test_control, all_test_treatment, hist_c, hist_e, cols2, False, verbose=False)\n",
    "    p_aft_reg = modify_with_ml_rate(all_test_control, all_test_treatment, hist_c, hist_e, cols3)\n",
    "    \n",
    "    \n",
    "    before.append(p_bef)\n",
    "    after_cup.append(p_aft_cup)\n",
    "    after_gb.append(p_aft_gb)\n",
    "    after_reg.append(p_aft_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'control_indexes_small' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/2520258834.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdraw_graphics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbefore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_cup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_gb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf'Маленькие фолды: {control_indexes_small[0].shape[0]}\\nМаленькая история: {hist_c.shape[0] + hist_e.shape[0]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'control_indexes_small' is not defined"
     ]
    }
   ],
   "source": [
    "draw_graphics(before, after_cup, after_gb, after_reg, title=f'Маленькие фолды: {control_indexes_small[0].shape[0]}\\nМаленькая история: {hist_c.shape[0] + hist_e.shape[0]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эксперимент по сравнению методов, описанный в разделе 3.4.1 отчета о НИР"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [400, 800, 1000, 1200, 1500, 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['f0', 'f2', 'f8', 'f9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данного эксперимента было сгенерированно по 10 стратифицированных подвыборок с размерами контрольной группы `400, 800, 1000, 1200, 1500, 2000`. На каждой паре подвыборки из тестовой и контрольной групп замерялось p-value до и после применения различных методов снижения дисперсии. По 10 запускам был оценен разброс значений. \n",
    "\n",
    "Генерация стратифицированных подвыборок проиводилась с помощью MultilabelStratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_control = df.loc[(df['treatment'] == 0) & (~df.index.isin(control_sample_hist.index))]\n",
    "# all_treatment = df.loc[(df['treatment'] == 1) & (~df.index.isin(treatment_sample_hist.index))]\n",
    "# scale = all_treatment.shape[0] / all_control.shape[0]\n",
    "\n",
    "#число повторений\n",
    "#n_repeats = 10\n",
    "\n",
    "# control_generators = []\n",
    "# treatment_generators = []\n",
    "\n",
    "# for size in tqdm(sizes):\n",
    "#     msss_control = MultilabelStratifiedShuffleSplit(n_splits=n_repeats, test_size=size, random_state=size + 5)\n",
    "#     msss_treatment = MultilabelStratifiedShuffleSplit(n_splits=n_repeats, test_size=int(size * scale), random_state=size + 5)\n",
    "    \n",
    "#     control_generator = msss_control.split(all_control.values, all_control.loc[:, columns].values)\n",
    "#     treatment_generator = msss_treatment.split(all_treatment.values, all_treatment.loc[:, columns].values)\n",
    "    \n",
    "#     control_indexes = list(control_generator)\n",
    "#     treatment_indexes = list(treatment_generator)\n",
    "    \n",
    "    \n",
    "#     data_control = []\n",
    "#     data_treatment = []\n",
    "\n",
    "#     for i in tqdm(range(0, len(control_indexes))):\n",
    "#         data_control.append(all_control.iloc[control_indexes[i][1]])\n",
    "#         data_treatment.append(all_treatment.iloc[treatment_indexes[i][1]])\n",
    "    \n",
    "#     print(control_indexes[0][1].shape)\n",
    "\n",
    "#     joblib.dump(data_control, f'control_data_split_{size}.joblib')\n",
    "#     joblib.dump(data_treatment, f'treatment_data_split_{size}.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация исторических данных. Из всего датасета удаляютсяя индексы объектов из тестовой и контрольной выборок одного размера, после чего из оставшихся объектов выбираются пользователи, составляющие исторический контекст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history_size = 1000\n",
    "# history_scale = scale\n",
    "\n",
    "# for size in tqdm(sizes):\n",
    "#     control_ind = joblib.load(f'control_data_split_{size}.joblib')\n",
    "#     treatment_ind = joblib.load(f'treatment_data_split_{size}.joblib')\n",
    "    \n",
    "#     all_in_slit_control = []\n",
    "#     all_in_slit_treatment = []\n",
    "    \n",
    "#     for i in range(0, len(control_ind)):\n",
    "#         all_in_slit_control.extend(control_ind[i].index)\n",
    "#         all_in_slit_treatment.extend(treatment_ind[i].index)\n",
    "        \n",
    "        \n",
    "#     all_control_for_hist = df.loc[(df['treatment'] == 0) & (~df.index.isin(all_in_slit_control))]\n",
    "#     all_treatment_for_hist = df.loc[(df['treatment'] == 1) & (~df.index.isin(all_in_slit_treatment))]\n",
    "     \n",
    "    \n",
    "#     msss_control = MultilabelStratifiedShuffleSplit(n_splits=10, test_size=history_size, random_state=size + 2)\n",
    "#     msss_treatment = MultilabelStratifiedShuffleSplit(n_splits=10, test_size=int(history_size * history_scale), random_state=size + 2)\n",
    "    \n",
    "#     control_generator = msss_control.split(all_control_for_hist.values, all_control_for_hist.loc[:, columns].values)\n",
    "#     treatment_generator = msss_treatment.split(all_treatment_for_hist.values, all_treatment_for_hist.loc[:, columns].values)\n",
    "    \n",
    "#     control_indexes = list(control_generator)\n",
    "#     treatment_indexes = list(treatment_generator)\n",
    "    \n",
    "#     print(control_indexes[0][1].shape)\n",
    "    \n",
    "#     hist_control_table = []\n",
    "#     hist_treatment_table = []\n",
    "    \n",
    "#     for i in range(0, len(control_indexes)):\n",
    "#         hist_control_table.append(all_control_for_hist.iloc[control_indexes[i][1]])\n",
    "#         hist_treatment_table.append(all_treatment_for_hist.iloc[treatment_indexes[i][1]])\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "#     joblib.dump(hist_control_table, f'control_data_hist_{size}.joblib')\n",
    "#     joblib.dump(hist_treatment_table, f'treatment_data_hist_{size}.joblib')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(sample_c, sample_t, history_c_ind, history_t_ind):\n",
    "    \"\"\"\n",
    "    Функция для запуска тестов\n",
    "\n",
    "    Параметры:\n",
    "        sample_c - list[DataFrame] - объекты контрольной группы\n",
    "        sample_t - list[DataFrame] - объекты тестовой группы\n",
    "        history_c_ind - list[DataFrame] - историческая выборка\n",
    "        history_t_ind - list[DataFrame] - историческая выборка\n",
    "        \n",
    "    Выход:\n",
    "        before - array - значения p-value без применения методов \n",
    "        after_cup - array - значения p-value после применения CUPED \n",
    "        after_gb - array - значения p-value после применения CUPAC  \n",
    "        after_reg - array - значения p-value после применения ML-rate  \n",
    "\n",
    "    \"\"\"\n",
    "    before = []\n",
    "    after_cup = []\n",
    "    after_gb = []\n",
    "    after_reg = []\n",
    "\n",
    "    cols1 = cols_regr_ordinal\n",
    "    cols2 = cols_boosting\n",
    "    cols3 = ['f4', 'f11', 'f2']\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(0, len(sample_c))):\n",
    "        test_control = sample_c[i]\n",
    "        test_treatment = sample_t[i]\n",
    "        \n",
    "        hist_control = history_c_ind[i]\n",
    "        hist_treatment = history_t_ind[i]\n",
    "        \n",
    "        \n",
    "        p_bef, p_after_cup = modify_with_cuped(test_control, test_treatment, hist_control, hist_treatment, cols1, True, encoder='Ord')\n",
    "        p_bef, p_after_gb = modify_with_cupac(test_control, test_treatment, hist_control, hist_treatment, cols2)\n",
    "        p_aft_reg = modify_with_ml_rate(test_control, test_treatment, hist_control, hist_treatment, cols3)\n",
    "\n",
    "        \n",
    "        before.append(p_bef)\n",
    "        after_cup.append(p_after_cup)\n",
    "        after_gb.append(p_after_gb)\n",
    "        after_reg.append(p_aft_reg)\n",
    "        \n",
    "    return np.array(before), np.array(after_cup), np.array(after_gb), np.array(after_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bcd9c6db9e4a0e996533d207ff7fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/2732774437.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtreatment_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mcontrol_ind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"saved_variables/control_data_split_{size}_{i}.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mtreatment_ind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"saved_variables/treatment_data_split_{size}_{i}.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[1;31m#  \"No module named 'pandas.core.sparse.series'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;31m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;31m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUnpicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STACK_GLOBAL requires str\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSTACK_GLOBAL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_stack_global\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_class_locations_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1579\u001b[0m         \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1581\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1582\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1583\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[1;34m(obj, name)\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             raise AttributeError(\"Can't get attribute {!r} on {!r}\"\n\u001b[0m\u001b[0;32m    332\u001b[0m                                  .format(name, obj)) from None\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>"
     ]
    }
   ],
   "source": [
    "#арзмеры генерируемых подвыборок\n",
    "sizes = [400, 800, 1000, 1200, 1500, 2000]\n",
    "#число генерируемых подвыборок\n",
    "n_repeats = 10\n",
    "\n",
    "pvals_b = []\n",
    "pvals_c = []\n",
    "pvals_gb = []\n",
    "pvals_reg = []\n",
    "\n",
    "# Загрузка сгенерированных данных в формате list[DataFrame] и запуск тестов\n",
    "for size in tqdm(sizes):\n",
    "    control_ind = []\n",
    "    treatment_ind = []\n",
    "    for i in range(n_repeats):\n",
    "        control_ind.append(pd.read_pickle(f\"saved_variables/control_data_split_{size}_{i}.pkl\"))\n",
    "        treatment_ind.append(pd.read_pickle(f\"saved_variables/treatment_data_split_{size}_{i}.pkl\"))\n",
    "\n",
    "    control_ind_hist = []\n",
    "    treatment_ind_hist = []\n",
    "    for i in range(n_repeats):\n",
    "        control_ind_hist.append(pd.read_pickle(f\"saved_variables/control_data_hist_{size}_{i}.pkl\"))\n",
    "        treatment_ind_hist.append(pd.read_pickle(f\"saved_variables/treatment_data_hist_{size}_{i}.pkl\"))\n",
    "    \n",
    "    b, c, gb, reg = run_test(control_ind, treatment_ind, control_ind_hist, treatment_ind_hist)\n",
    "    pvals_b.append(b)\n",
    "    pvals_c.append(c)\n",
    "    pvals_gb.append(gb)\n",
    "    pvals_reg.append(reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модификации для отрисовки графика\n",
    "\n",
    "pvals_c = pd.DataFrame(pvals_c)\n",
    "pvals_c = pvals_c.set_axis(sizes)\n",
    "\n",
    "pvals_gb = pd.DataFrame(pvals_gb)\n",
    "pvals_gb = pvals_gb.set_axis(sizes)\n",
    "\n",
    "pvals_b = pd.DataFrame(pvals_b)\n",
    "pvals_b = pvals_b.set_axis(sizes)\n",
    "\n",
    "pvals_reg = pd.DataFrame(pvals_reg)\n",
    "pvals_reg = pvals_reg.set_axis(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cuped = None\n",
    "for i in range(pvals_c.shape[1]):\n",
    "    data_cuped = pd.concat([data_cuped, pvals_c.iloc[:, i]])\n",
    "    \n",
    "data_grad_boost = None\n",
    "for i in range(pvals_gb.shape[1]):\n",
    "    data_grad_boost = pd.concat([data_grad_boost, pvals_gb.iloc[:, i]])\n",
    "    \n",
    "    \n",
    "data_before = None\n",
    "for i in range(pvals_b.shape[1]):\n",
    "    data_before = pd.concat([data_before, pvals_b.iloc[:, i]])\n",
    "\n",
    "data_reg = None\n",
    "for i in range(pvals_reg.shape[1]):\n",
    "    data_reg = pd.concat([data_reg, pvals_reg.iloc[:, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.subplots(1, figsize=(10, 7))\n",
    "sns.lineplot(data=data_cuped, label='CUPED', marker=\"o\", markersize=7, color='#3399ff')\n",
    "sns.lineplot(data=data_grad_boost, label='CUPAC', marker=\"o\", markersize=7, color='#009900')\n",
    "sns.lineplot(data=data_before, label='Default', marker=\"o\", markersize=7, color='#ff9933')\n",
    "sns.lineplot(data=data_reg, label='Ml-rate', marker=\"o\", markersize=7, color='#ff66ff')\n",
    "plt.plot(sizes, [0.05] * len(sizes), color=\"#ff0000\", linestyle='dashed', label='alpha')\n",
    "# plt.title('Зависимость параметра p-value оцененного по 10 запускам от размера выборки')\n",
    "plt.xlabel('Размер контрольной выборки')\n",
    "plt.ylabel('p-value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/A тест на данных Criteo из раздела 3.6 отчета о НИР."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной секции мы проверяем, что методы снижения дисперсии CUPED/CUPAC/ML-RATE не приводят к ложноположительным результатам T-теста. Для этого мы анализируем работу методов на выборках без статистически значимой разницы: проводим T-тест на двух контрольных подвыборках одинакового размера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_AA(sample, history, n_pairs=45):\n",
    "    \"\"\"\n",
    "    Функция для запуск методов на всех парах одинакового размера из котнтрольной группы.        \n",
    "    \n",
    "    Параметры:\n",
    "        sample - list[DataFrame] - объекты контрольной группы\n",
    "        history - list[DataFrame] - историческая выборка\n",
    "        \n",
    "    Выход:\n",
    "        before - array - значения p-value без применения методов \n",
    "        after_cup - array - значения p-value после применения CUPED \n",
    "        after_gb - array - значения p-value после применения CUPAC  \n",
    "        after_reg - array - значения p-value после применения ML-rate  \n",
    "\n",
    "    \"\"\"\n",
    "    before = []\n",
    "    after_cup = []\n",
    "    after_gb = []\n",
    "    after_reg = []\n",
    "\n",
    "    cols1 = cols_regr_ordinal\n",
    "    cols2 = cols_boosting\n",
    "    cols3 = ['f4', 'f11', 'f2']\n",
    "    \n",
    "    indexes = list(range(0, len(sample)))\n",
    "\n",
    "    pairs = np.array(list((itertools.combinations(indexes, 2))))\n",
    "    chosen_indexes = np.random.choice(np.arange(0, len(pairs)), n_pairs, replace=False)\n",
    "    chosen_pairs = pairs[chosen_indexes]\n",
    "    \n",
    "    for pair in tqdm(chosen_pairs):\n",
    "        test_control = sample[pair[0]]\n",
    "        test_treatment = sample[pair[1]]\n",
    "        \n",
    "        hist_control = history[pair[0]]\n",
    "        hist_treatment = history[pair[1]]\n",
    "        \n",
    "        p_bef, p_after_cup = modify_with_cuped(test_control, test_treatment, hist_control, hist_treatment, cols1, True, encoder='Ord')\n",
    "        p_bef, p_after_gb = modify_with_cupac(test_control, test_treatment, hist_control, hist_treatment, cols2)\n",
    "        p_aft_reg = modify_with_ml_rate(test_control, test_treatment, hist_control, hist_treatment, cols3, aa=True)\n",
    "        \n",
    "        before.append(p_bef)\n",
    "        after_cup.append(p_after_cup)\n",
    "        after_gb.append(p_after_gb)\n",
    "        after_reg.append(p_aft_reg)\n",
    "        \n",
    "    return np.array(before), np.array(after_cup), np.array(after_gb), np.array(after_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb6c04ee4d7435e82da31ce10a4b3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/2682009542.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mcontrol_ind_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mcontrol_ind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"saved_variables/control_data_split_{size}_notarget_{i}.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mcontrol_ind_hist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"saved_variables/control_data_hist_{size}_notarget_{i}.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[1;31m#  \"No module named 'pandas.core.sparse.series'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;31m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;31m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mload_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUnpicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STACK_GLOBAL requires str\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSTACK_GLOBAL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_stack_global\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\compat\\pickle_compat.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_class_locations_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36mfind_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1579\u001b[0m         \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1581\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1582\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1583\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_getattribute\u001b[1;34m(obj, name)\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             raise AttributeError(\"Can't get attribute {!r} on {!r}\"\n\u001b[0m\u001b[0;32m    332\u001b[0m                                  .format(name, obj)) from None\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_block' on <module 'pandas._libs.internals' from 'C:\\\\Anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\_libs\\\\internals.cp39-win_amd64.pyd'>"
     ]
    }
   ],
   "source": [
    "# Запуск методов на данных без статистически значимой разницы\n",
    "# control_ind - list[DataFrame] - контрольная выборка\n",
    "# control_ind_hist - list[DataFrame] - исторические выборки\n",
    "# На выходе - 4 array[list[float]] - 4 листа с значением p-value для каждого метода для каждой пары\n",
    "\n",
    "sizes = [400, 800, 1000, 1200, 1500, 2000]\n",
    "\n",
    "pvals_b = []\n",
    "pvals_c = []\n",
    "pvals_gb = []\n",
    "pvals_reg = []\n",
    "\n",
    "for size in tqdm(sizes):    \n",
    "    control_ind = []\n",
    "    control_ind_hist = []\n",
    "    for i in range(n_repeats):\n",
    "        control_ind.append(pd.read_pickle(f\"saved_variables/control_data_split_{size}_notarget_{i}.pkl\"))\n",
    "        control_ind_hist.append(pd.read_pickle(f\"saved_variables/control_data_hist_{size}_notarget_{i}.pkl\"))\n",
    "    \n",
    "    b, c, gb, reg = run_test_AA(control_ind, control_ind_hist)\n",
    "    \n",
    "    pvals_b.append(b)\n",
    "    pvals_c.append(c)\n",
    "    pvals_gb.append(gb)\n",
    "    pvals_reg.append(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модификациии для отрисовки графика\n",
    "\n",
    "pvals_c = pd.DataFrame(pvals_c)\n",
    "pvals_c = pvals_c.set_axis(sizes)\n",
    "\n",
    "pvals_gb = pd.DataFrame(pvals_gb)\n",
    "pvals_gb = pvals_gb.set_axis(sizes)\n",
    "\n",
    "pvals_b = pd.DataFrame(pvals_b)\n",
    "pvals_b = pvals_b.set_axis(sizes)\n",
    "\n",
    "pvals_reg = pd.DataFrame(pvals_reg)\n",
    "pvals_reg = pvals_reg.set_axis(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модификациии для отрисовки графика\n",
    "\n",
    "data_cuped = None\n",
    "for i in range(pvals_c.shape[1]):\n",
    "    data_cuped = pd.concat([data_cuped, pvals_c.iloc[:, i]])\n",
    "    \n",
    "data_grad_boost = None\n",
    "for i in range(pvals_gb.shape[1]):\n",
    "    data_grad_boost = pd.concat([data_grad_boost, pvals_gb.iloc[:, i]])\n",
    "    \n",
    "    \n",
    "data_before = None\n",
    "for i in range(pvals_b.shape[1]):\n",
    "    data_before = pd.concat([data_before, pvals_b.iloc[:, i]])\n",
    "\n",
    "data_reg = None\n",
    "for i in range(pvals_reg.shape[1]):\n",
    "    data_reg = pd.concat([data_reg, pvals_reg.iloc[:, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.subplots(1, figsize=(10, 7))\n",
    "sns.lineplot(data=data_cuped, label='CUPED', marker=\"o\", markersize=7, color='#3399ff')\n",
    "sns.lineplot(data=data_grad_boost, label='CUPAC', marker=\"o\", markersize=7, color='#009900')\n",
    "sns.lineplot(data=data_before, label='Default', marker=\"o\", markersize=7, color='#ff9933')\n",
    "sns.lineplot(data=data_reg, label='Ml-rate', marker=\"o\", markersize=7, color='#ff66ff')\n",
    "\n",
    "plt.plot(sizes, [0.05] * len(sizes), color=\"#ff0000\", linestyle='dashed', label='alpha')\n",
    "# plt.title('Зависимость параметра p-value оцененного по 10 запускам от размера выборки')\n",
    "plt.xlabel('Размер контрольной выборки')\n",
    "plt.ylabel('p-value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
